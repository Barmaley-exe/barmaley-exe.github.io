<!DOCTYPE html>
<html lang="en">
<head>
  <title>Posts tagged computer science - B.log</title>
  <meta charset="utf-8" />
  <link rel="shortcut icon" href="../favicon.ico" />

  <link rel="stylesheet" type="text/css" href="../css/default.css" />
  <link rel="stylesheet" type="text/css" href="../css/syntax.css" />
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
    <header>
      <hgroup>
        <h1><a href="../">B.log</a></h1>
        <h2>Random notes on Computer Science, Mathematics and Software Engineering</h2>
      </hgroup>
    </header>
    <nav>
        <menu>
          <a href="../">Home</a>
          <a href="../pages/about.html">About me</a>
          <a href="http://feeds.feedburner.com/barmaley-exe-blog-feed">RSS feed</a>
        </menu>
    </nav>
    <section>
        <h1>Posts tagged computer science</h1>
<ul>
    <article>
	<header>
		<h3><a href="../posts/2014-05-01-on-sorting-complexity.html">On Sorting Complexity</a></h3>
		<time>May  1, 2014</time>
	</header>

	<section>
		<p>It’s well known that lower bound for sorting problem (in general case) is $ O(n log n) $. The proof I was taught is somewhat involved and is based on paths in “decision” trees. Recently I’ve discovered an information-theoretic approach (or reformulation) to that proof.</p>

	</section>
</article>

<hr />

</ul>

    </section>
    <footer>
        <a href="http://jaspervdj.be/hakyll/index.html">Generated with Hakyll</a>
    </footer>

<script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-38530232-1']);
_gaq.push(['_trackPageview']);
(function() {
 var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
 ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
 var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>
</body>
</html>
